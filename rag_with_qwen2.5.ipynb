{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "llm-explanation",
   "metadata": {},
   "source": [
    "# Understanding Large Language Models (LLMs)\n",
    "\n",
    "Large Language Models (LLMs) are advanced AI systems trained on vast amounts of text data. They use deep learning architectures, primarily based on the Transformer model, to understand and generate human-like text.\n",
    "\n",
    "## How Text Generation Works Internally\n",
    "\n",
    "Text generation in LLMs follows these key steps:\n",
    "\n",
    "1. **Tokenization**: The input text is split into tokens (words or subwords)\n",
    "2. **Embedding**: Tokens are converted into numerical vectors\n",
    "3. **Attention Mechanism**: The model uses self-attention to understand relationships between tokens\n",
    "4. **Hidden State Processing**: Information flows through multiple transformer layers\n",
    "5. **Token Prediction**: The model predicts the next token based on probability distributions\n",
    "6. **Generation Loop**: Steps 4-5 repeat until the response is complete\n",
    "\n",
    "Key parameters that influence generation:\n",
    "- Temperature: Controls randomness in generation\n",
    "- Top-p (nucleus sampling): Filters the cumulative probability distribution\n",
    "- Context window: Maximum number of tokens the model can process\n",
    "\n",
    "# Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "RAG is an architecture that enhances LLM responses by combining them with relevant information retrieved from a knowledge base. This approach offers several benefits:\n",
    "\n",
    "1. **Improved Accuracy**: Models can access specific, up-to-date information\n",
    "2. **Reduced Hallucination**: Responses are grounded in retrieved facts\n",
    "3. **Domain Adaptation**: Can be specialized for specific use cases\n",
    "4. **Cost Efficiency**: Smaller models can perform well with good retrieval\n",
    "\n",
    "## RAG Pipeline Components:\n",
    "\n",
    "1. **Document Processing**: Converting documents into chunks\n",
    "2. **Embedding Generation**: Creating vector representations\n",
    "3. **Vector Storage**: Efficient storage and retrieval of embeddings\n",
    "4. **Retrieval**: Finding relevant context for queries\n",
    "5. **Augmented Generation**: Combining retrieved context with LLM generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-configuration-explanation",
   "metadata": {},
   "source": [
    "# Model Configuration\n",
    "\n",
    "Below we set up the Qwen 2.5 7B model using Ollama. The configuration includes:\n",
    "- Temperature and top_p for controlling generation diversity\n",
    "- Context window size\n",
    "- Streaming callback for real-time output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initialize-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis.sanmartin\\AppData\\Local\\Temp\\ipykernel_10748\\1937206305.py:3: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = Ollama(\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "MODEL = \"qwen2.5:7b\"\n",
    "llm = Ollama(\n",
    "    model=MODEL,\n",
    "    temperature=0.9,\n",
    "    top_p=0.9,\n",
    "    num_ctx=4096,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-processing-explanation",
   "metadata": {},
   "source": [
    "# Data Processing and Embedding Generation\n",
    "\n",
    "This section demonstrates:\n",
    "1. Loading and preprocessing JSON data\n",
    "2. Text chunking for optimal retrieval\n",
    "3. Generating embeddings using HuggingFace's sentence transformers\n",
    "4. Storing vectors in ChromaDB for efficient retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "create-embeddings-huggingface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['device_id', 'timestamp', 'bandwidth_mbps', 'latency_ms', 'packet_loss', 'signal_strength_dbm', 'cell_id', 'connection_type']\n",
      "Generated 1000 text chunks.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>bandwidth_mbps</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>packet_loss</th>\n",
       "      <th>signal_strength_dbm</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>connection_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5851</td>\n",
       "      <td>2024-12-13T14:46:24.173261</td>\n",
       "      <td>536.156239</td>\n",
       "      <td>6.551220</td>\n",
       "      <td>0.037045</td>\n",
       "      <td>-101.327696</td>\n",
       "      <td>57</td>\n",
       "      <td>MIMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4856</td>\n",
       "      <td>2024-12-13T15:46:24.173271</td>\n",
       "      <td>485.536208</td>\n",
       "      <td>9.675234</td>\n",
       "      <td>0.040759</td>\n",
       "      <td>-99.914445</td>\n",
       "      <td>66</td>\n",
       "      <td>MIMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3914</td>\n",
       "      <td>2024-12-13T16:46:24.173273</td>\n",
       "      <td>420.810843</td>\n",
       "      <td>8.836038</td>\n",
       "      <td>0.049106</td>\n",
       "      <td>-98.675641</td>\n",
       "      <td>59</td>\n",
       "      <td>MIMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9267</td>\n",
       "      <td>2024-12-13T17:46:24.173274</td>\n",
       "      <td>736.451439</td>\n",
       "      <td>8.656040</td>\n",
       "      <td>0.056578</td>\n",
       "      <td>-80.390779</td>\n",
       "      <td>68</td>\n",
       "      <td>Carrier Aggregation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4908</td>\n",
       "      <td>2024-12-13T18:46:24.173275</td>\n",
       "      <td>524.275720</td>\n",
       "      <td>11.614536</td>\n",
       "      <td>0.022364</td>\n",
       "      <td>-109.168636</td>\n",
       "      <td>98</td>\n",
       "      <td>MIMO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   device_id                   timestamp  bandwidth_mbps  latency_ms  \\\n",
       "0       5851  2024-12-13T14:46:24.173261      536.156239    6.551220   \n",
       "1       4856  2024-12-13T15:46:24.173271      485.536208    9.675234   \n",
       "2       3914  2024-12-13T16:46:24.173273      420.810843    8.836038   \n",
       "3       9267  2024-12-13T17:46:24.173274      736.451439    8.656040   \n",
       "4       4908  2024-12-13T18:46:24.173275      524.275720   11.614536   \n",
       "\n",
       "   packet_loss  signal_strength_dbm  cell_id      connection_type  \n",
       "0     0.037045          -101.327696       57                 MIMO  \n",
       "1     0.040759           -99.914445       66                 MIMO  \n",
       "2     0.049106           -98.675641       59                 MIMO  \n",
       "3     0.056578           -80.390779       68  Carrier Aggregation  \n",
       "4     0.022364          -109.168636       98                 MIMO  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load JSON file locally (ensure this file is in the same folder or provide full path)\n",
    "json_file = \"json_dataset.json\"\n",
    "\n",
    "# Read JSON file asynchronously\n",
    "with open(json_file, \"r\") as f:\n",
    "    contents = f.read()\n",
    "    json_data = json.loads(contents)\n",
    "\n",
    "# Extract records based on JSON structure\n",
    "if isinstance(json_data, dict) and \"data\" in json_data:\n",
    "    # If MongoDB structure\n",
    "    records = json_data[\"data\"]\n",
    "elif isinstance(json_data, list):\n",
    "    # If direct list of records\n",
    "    records = json_data\n",
    "else:\n",
    "    # If single record\n",
    "    records = [json_data]\n",
    "\n",
    "# Convert records to DataFrame and clean\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Remove unwanted columns if they exist\n",
    "columns_to_drop = ['_id', 'dataset_id']\n",
    "df_original = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')\n",
    "\n",
    "# Get resulting columns\n",
    "fields = df_original.columns.tolist()\n",
    "print(fields)\n",
    "\n",
    "# Create documents for embeddings (concatenate columns into a string)\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    doc_text = \" \".join([f\"{col}: {val}\" for col, val in row.items()])\n",
    "    documents.append(doc_text)\n",
    "\n",
    "# Create splitter for dividing long texts into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,        \n",
    "    chunk_overlap=50       \n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "split_docs = []\n",
    "for doc in documents:\n",
    "    split_docs.extend(text_splitter.split_text(doc))\n",
    "\n",
    "# Define HuggingFace embeddings model\n",
    "EMBEDDINGS_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDINGS_MODEL)\n",
    "\n",
    "# Create and save embeddings in ChromaDB\n",
    "db = Chroma.from_texts(texts=split_docs, embedding=embeddings)\n",
    "\n",
    "# Verify number of generated chunks\n",
    "print(f\"Generated {len(split_docs)} text chunks.\")\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rag-setup-explanation",
   "metadata": {},
   "source": [
    "# RAG Chain Setup\n",
    "\n",
    "Here we configure the RAG pipeline by:\n",
    "1. Setting up the retriever\n",
    "2. Defining the prompt template\n",
    "3. Creating the QA chain that combines retrieval and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rag-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"device_id\": 1234,\n",
      "      \"timestamp\": \"2025-01-04T10:00:00.000000\",\n",
      "      \"bandwidth_mbps\": 200.5,\n",
      "      \"latency_ms\": 9.8,\n",
      "      \"packet_loss\": 0.01,\n",
      "      \"signal_strength_dbm\": -97.5,\n",
      "      \"cell_id\": 30,\n",
      "      \"connection_type\": \"4G\"\n",
      "    },\n",
      "    {\n",
      "      \"device_id\": 5678,\n",
      "      \"timestamp\": \"2025-01-04T11:00:00.000000\",\n",
      "      \"bandwidth_mbps\": 220.3,\n",
      "      \"latency_ms\": 11.2,\n",
      "      \"packet_loss\": 0.02,\n",
      "      \"signal_strength_dbm\": -95.8,\n",
      "      \"cell_id\": 45,\n",
      "      \"connection_type\": \"5G\"\n",
      "    },\n",
      "    {\n",
      "      \"device_id\": 9101,\n",
      "      \"timestamp\": \"2025-01-04T12:00:00.000000\",\n",
      "      \"bandwidth_mbps\": 180.7,\n",
      "      \"latency_ms\": 8.6,\n",
      "      \"packet_loss\": 0.005,\n",
      "      \"signal_strength_dbm\": -93.4,\n",
      "      \"cell_id\": 25,\n",
      "      \"connection_type\": \"Carrier Aggregation\"\n",
      "    }\n",
      "  ]\n",
      "}"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Generate a table with 3 rows, random values and the following fields device_id, timestamp, bandwidth_mbps, latency_ms, packet_loss, signal_strength_dbm, cell_id, connection_type. Respond ONLY with pure JSON, no markdown, no triple quotes, no explanations.',\n",
       " 'result': '{\\n  \"data\": [\\n    {\\n      \"device_id\": 1234,\\n      \"timestamp\": \"2025-01-04T10:00:00.000000\",\\n      \"bandwidth_mbps\": 200.5,\\n      \"latency_ms\": 9.8,\\n      \"packet_loss\": 0.01,\\n      \"signal_strength_dbm\": -97.5,\\n      \"cell_id\": 30,\\n      \"connection_type\": \"4G\"\\n    },\\n    {\\n      \"device_id\": 5678,\\n      \"timestamp\": \"2025-01-04T11:00:00.000000\",\\n      \"bandwidth_mbps\": 220.3,\\n      \"latency_ms\": 11.2,\\n      \"packet_loss\": 0.02,\\n      \"signal_strength_dbm\": -95.8,\\n      \"cell_id\": 45,\\n      \"connection_type\": \"5G\"\\n    },\\n    {\\n      \"device_id\": 9101,\\n      \"timestamp\": \"2025-01-04T12:00:00.000000\",\\n      \"bandwidth_mbps\": 180.7,\\n      \"latency_ms\": 8.6,\\n      \"packet_loss\": 0.005,\\n      \"signal_strength_dbm\": -93.4,\\n      \"cell_id\": 25,\\n      \"connection_type\": \"Carrier Aggregation\"\\n    }\\n  ]\\n}'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "# Define base prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a cybersecurity expert. Based on this dataset and its fields\n",
    "    {context}\n",
    "\n",
    "    Answer the user's question:\n",
    "    {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Configure RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")\n",
    "\n",
    "# Build dynamic question with fields\n",
    "fields_str = ', '.join(fields)\n",
    "num_samples = 3\n",
    "\n",
    "# Example system query\n",
    "question = f\"Generate a table with {num_samples} rows, random values and the following fields {fields_str}. Respond ONLY with pure JSON, no markdown, no triple quotes, no explanations.\"\n",
    "response = rag_chain.invoke(question)\n",
    "display(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-processing-explanation-2",
   "metadata": {},
   "source": [
    "# Data Processing and Export\n",
    "\n",
    "Finally, we process the generated data by:\n",
    "1. Extracting and cleaning the JSON response\n",
    "2. Converting to a pandas DataFrame\n",
    "3. Exporting to CSV for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "process-output",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>bandwidth_mbps</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>packet_loss</th>\n",
       "      <th>signal_strength_dbm</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>connection_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234</td>\n",
       "      <td>2025-01-04T10:00:00.000000</td>\n",
       "      <td>200.5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-97.5</td>\n",
       "      <td>30</td>\n",
       "      <td>4G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5678</td>\n",
       "      <td>2025-01-04T11:00:00.000000</td>\n",
       "      <td>220.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-95.8</td>\n",
       "      <td>45</td>\n",
       "      <td>5G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9101</td>\n",
       "      <td>2025-01-04T12:00:00.000000</td>\n",
       "      <td>180.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-93.4</td>\n",
       "      <td>25</td>\n",
       "      <td>Carrier Aggregation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   device_id                   timestamp  bandwidth_mbps  latency_ms  \\\n",
       "0       1234  2025-01-04T10:00:00.000000           200.5         9.8   \n",
       "1       5678  2025-01-04T11:00:00.000000           220.3        11.2   \n",
       "2       9101  2025-01-04T12:00:00.000000           180.7         8.6   \n",
       "\n",
       "   packet_loss  signal_strength_dbm  cell_id      connection_type  \n",
       "0        0.010                -97.5       30                   4G  \n",
       "1        0.020                -95.8       45                   5G  \n",
       "2        0.005                -93.4       25  Carrier Aggregation  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Extract and clean 'result' field\n",
    "raw_result = response['result']\n",
    "\n",
    "# Parse the JSON string in the 'result' field\n",
    "parsed_result = json.loads(raw_result)\n",
    "\n",
    "# Extract the \"data\" field, which contains the list of records\n",
    "data = parsed_result.get(\"data\", [])\n",
    "\n",
    "# Convert the extracted data into a pandas DataFrame\n",
    "df_generated = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv = \"output.csv\"\n",
    "df_generated.to_csv(output_csv, index=False)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_generated.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "# Conclusion and Next Steps\n",
    "\n",
    "This notebook demonstrates a basic RAG implementation. You can extend it by:\n",
    "1. Integrating different LLMs and embedding models\n",
    "2. Experimenting with various vector databases\n",
    "3. Adding evaluation metrics\n",
    "4. Implementing caching and optimization\n",
    "5. Adding error handling and validation\n",
    "\n",
    "The combination of LLMs with RAG provides a powerful foundation for building knowledge-intensive applications while maintaining accuracy and relevance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
